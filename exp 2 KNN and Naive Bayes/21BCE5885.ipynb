{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2db66c83",
      "metadata": {},
      "source": [
        "# KNN And Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76a80b9",
      "metadata": {
        "id": "f76a80b9"
      },
      "source": [
        "## Importing Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1a6b7280",
      "metadata": {
        "id": "1a6b7280"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   income  expected_income  risk_score   quality\n",
            "0    3135              550       36200  0.580918\n",
            "1    3180              600       30150  0.730720\n",
            "2    1540              450       34550  0.531712\n",
            "3    5230              700       42150  0.792552\n",
            "4    3590             1100       53850  0.744634\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_path = \"Z:\\\\Machine-Learning-Lab\\\\exp 2 KNN and Naive Bayes\\\\data.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "df.drop(columns=['emp_id'], inplace=True)\n",
        "print(df.head())\n",
        "X = df.drop(columns=['risk_score'])\n",
        "y = df['risk_score']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e8ae73",
      "metadata": {
        "id": "f1e8ae73"
      },
      "source": [
        "## Spliting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1fa82398",
      "metadata": {
        "id": "1fa82398"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b431a7db",
      "metadata": {
        "id": "b431a7db"
      },
      "source": [
        "## Finding train and test accuracy with Euclidean,Manhattan,Minkowski distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7a1778a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7a1778a",
        "outputId": "96eda207-7866-4e34-e49e-5e06f5a80790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distance Metric: euclidean\n",
            "Train Accuracy: 0.33421750663129973\n",
            "Test Accuracy: 0.0008375209380234506\n",
            "\n",
            "Distance Metric: manhattan\n",
            "Train Accuracy: 0.3339382940108893\n",
            "Test Accuracy: 0.0008375209380234506\n",
            "\n",
            "Distance Metric: minkowski\n",
            "Train Accuracy: 0.33421750663129973\n",
            "Test Accuracy: 0.0008375209380234506\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def evaluate_knn_classifier(X_train, X_test, y_train, y_test, n_neighbors, distance_metric):\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors, metric=distance_metric)\n",
        "    knn_classifier.fit(X_train, y_train)\n",
        "    train_pred = knn_classifier.predict(X_train)\n",
        "    test_pred = knn_classifier.predict(X_test)\n",
        "    train_accuracy = accuracy_score(y_train, train_pred)\n",
        "    test_accuracy = accuracy_score(y_test, test_pred)\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "n_neighbors = 3\n",
        "distance_metrics = ['euclidean', 'manhattan', 'minkowski']\n",
        "\n",
        "for metric in distance_metrics:\n",
        "    train_acc, test_acc = evaluate_knn_classifier(X_train, X_test, y_train, y_test, n_neighbors, metric)\n",
        "    print(f\"Distance Metric: {metric}\")\n",
        "    print(f\"Train Accuracy: {train_acc}\")\n",
        "    print(f\"Test Accuracy: {test_acc}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a63d530",
      "metadata": {
        "id": "2a63d530"
      },
      "source": [
        "## Optimal K value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "17438453",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17438453",
        "outputId": "2c885548-c471-4011-97c8-d64421ea0ac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal K value: 10\n",
            "Test Accuracy with Optimal K: 0.0013958682300390843\n"
          ]
        }
      ],
      "source": [
        "def find_optimal_k(X_train, X_test, y_train, y_test, max_k, distance_metric):\n",
        "    best_k = 0\n",
        "    best_test_accuracy = 0\n",
        "    for k in range(1, max_k + 1):\n",
        "        _, test_acc = evaluate_knn_classifier(X_train, X_test, y_train, y_test, k, distance_metric)\n",
        "        if test_acc > best_test_accuracy:\n",
        "            best_test_accuracy = test_acc\n",
        "            best_k = k\n",
        "    return best_k, best_test_accuracy\n",
        "\n",
        "# Find optimal K value\n",
        "max_k = 12\n",
        "optimal_k, optimal_test_accuracy = find_optimal_k(X_train, X_test, y_train, y_test, max_k, 'euclidean')\n",
        "print(f\"Optimal K value: {optimal_k}\")\n",
        "print(f\"Test Accuracy with Optimal K: {optimal_test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf02108",
      "metadata": {
        "id": "1cf02108"
      },
      "source": [
        "## Rebuild KNN classifier with The Optimal K: (i.e. find the best clusetering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3bd87573",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bd87573",
        "outputId": "942c958d-e152-4ef6-9091-826303e9eb5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (Regression): 235494991.5410385\n"
          ]
        }
      ],
      "source": [
        "optimal_knn_classifier = KNeighborsClassifier(n_neighbors=optimal_k, metric='euclidean')\n",
        "optimal_knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust n_neighbors\n",
        "knn_regressor.fit(X_train, y_train)\n",
        "y_pred_regression = knn_regressor.predict(X_test)\n",
        "mse_regression = mean_squared_error(y_test, y_pred_regression)\n",
        "print(f\"Mean Squared Error (Regression): {mse_regression}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99273ea7",
      "metadata": {
        "id": "99273ea7"
      },
      "source": [
        "## Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a6336741",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "a6336741",
        "outputId": "c2734f49-8388-494a-e234-78d0dfb015ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OptimaI k for regression: 20\n",
            "Best RA2 Score for regression: 0.0760\n",
            "Mean Squared Error for regression: 2016074.5869\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "y_reg = df['income']\n",
        "X_reg = df.drop(columns=['income'])\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg,test_size=0.2,random_state=42)\n",
        "best_k =1\n",
        "best_r2 = float('-inf')\n",
        "best_mse = float('inf')\n",
        "for k in range(1, 21):\n",
        "    knn_reg = KNeighborsRegressor(n_neighbors=k)\n",
        "    knn_reg.fit(X_train_reg, y_train_reg)\n",
        "    y_pred_reg = knn_reg.predict(X_test_reg)\n",
        "    r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "    mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "    if r2 > best_r2 and mse < best_mse:\n",
        "        best_r2 = r2\n",
        "        best_mse = mse\n",
        "        best_k = k\n",
        "knn_reg_best = KNeighborsRegressor(n_neighbors=best_k)\n",
        "knn_reg_best.fit(X_train_reg, y_train_reg)\n",
        "y_pred_reg_best = knn_reg_best.predict(X_test_reg)\n",
        "r2_best = r2_score(y_test_reg, y_pred_reg_best)\n",
        "mse_best = mean_squared_error(y_test_reg, y_pred_reg_best)\n",
        "print(f\"OptimaI k for regression: {best_k}\")\n",
        "print(f\"Best RA2 Score for regression: {r2_best:.4f}\")\n",
        "print(f\"Mean Squared Error for regression: {mse_best:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a1097d",
      "metadata": {},
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ce6764",
      "metadata": {},
      "source": [
        "##  Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3ce152af",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f23f7d9",
      "metadata": {},
      "source": [
        "## Generate Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4d30ebe9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_data(n_samples, n_features, n_classes):\n",
        "    X = np.random.rand(n_samples, n_features)\n",
        "    y = np.random.randint(0, n_classes, size=n_samples)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9a60b0b",
      "metadata": {},
      "source": [
        "# Compute Frequency Table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff849614",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "094ef57f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_frequency_table(y):\n",
        "    frequency_table = pd.value_counts(y) / len(y)\n",
        "    return frequency_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf59110",
      "metadata": {},
      "source": [
        "## Train Naive Bayes Classifiers and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "95e4202e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "    # Gaussian Naive Bayes\n",
        "    gnb = GaussianNB()\n",
        "    gnb.fit(X_train, y_train)\n",
        "    gnb_predictions = gnb.predict(X_test)\n",
        "    # Multinomial Naive Bayes\n",
        "    mnb = MultinomialNB()\n",
        "    mnb.fit(X_train, y_train)\n",
        "    mnb_predictions = mnb.predict(X_test)\n",
        "    # Bernoulli Naive Bayes\n",
        "    bnb = BernoulliNB()\n",
        "    bnb.fit(X_train, y_train)\n",
        "    bnb_predictions = bnb.predict(X_test)\n",
        "    gnb_confusion_matrix = confusion_matrix(y_test, gnb_predictions)\n",
        "    mnb_confusion_matrix = confusion_matrix(y_test, mnb_predictions)\n",
        "    bnb_confusion_matrix = confusion_matrix(y_test, bnb_predictions)\n",
        "    return gnb_confusion_matrix, mnb_confusion_matrix, bnb_confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9c4aa7e",
      "metadata": {},
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7b0cf12e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frequency Table:\n",
            "1    0.535\n",
            "0    0.465\n",
            "Name: count, dtype: float64\n",
            "\n",
            "Gaussian Naive Bayes Confusion Matrix:\n",
            "\n",
            "MultinomiaI Naive Bayes Confusion Matrix:\n",
            "[[  0  86]\n",
            " [  0 114]]\n",
            "\n",
            "Bernoulli Naive Bayes Confusion Matrix:\n",
            "[[  0  86]\n",
            " [  0 114]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\guhan\\AppData\\Local\\Temp\\ipykernel_16712\\1884895217.py:2: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
            "  frequency_table = pd.value_counts(y) / len(y)\n"
          ]
        }
      ],
      "source": [
        "# Generate synthetic data\n",
        "n_samples = 1000\n",
        "n_features = 10\n",
        "n_classes = 2\n",
        "X, y = generate_data(n_samples, n_features, n_classes)\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Train and evaluate classifiers\n",
        "gnb_confusion_matrix, mnb_confusion_matrix, bnb_confusion_matrix = train_and_evaluate(X_train, X_test, y_train, y_test)\n",
        "# Compute frequency table\n",
        "frequency_table = compute_frequency_table(y)\n",
        "# Print results\n",
        "print(\"Frequency Table:\")\n",
        "print(frequency_table)\n",
        "print(\"\\nGaussian Naive Bayes Confusion Matrix:\")\n",
        "print(\"\\nMultinomiaI Naive Bayes Confusion Matrix:\")\n",
        "print(mnb_confusion_matrix)\n",
        "print(\"\\nBernoulli Naive Bayes Confusion Matrix:\")\n",
        "print(bnb_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce2c91f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
